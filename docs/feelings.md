# 心得

本项目是MindSpore开源实习项目的一部分，目的是复现MaskTextSpotter v3规格的模型，实现端到端的文字识别功能。总体而言，前期分析和开发比较顺利，目前已经完成开发项目代码和测试部分关键模块，从中也积累到了许多经验和能力。

首先，以数据的流向为导向，我逐步理解了用MindSpore开发模型的逻辑。在开发复现过程中，以数据为视角，与pytorch的执行流程比对，一步步递归构建模型。以数据的视角，首先进入backbone处理，而backbone处理完成后再把数据传向spn生成proposal，因此先开发完成backbone在到spn。在其中遇到一些必须的模块，先暂停目前的开发而转向特殊模块的开发。事实证明，这种方法开发的模型比较完整，不会提示缺了某个模块而报错，但是需要集中注意力，理清递归开发模型的逻辑。

其次，在模块开发的过程中，算子的转换是不可或缺的一部分，因此强大的文档检索能力是提高效率必备的方法。虽然MindSpore与传统的PyTorch和TensorFlow一样都是深度学习框架的一种，但是在api或者算子的定义和行为上面还是会存在一些区别。在面对这些区别时，我都会将mindspore和pytorch的官方文档打开，查询pytorch算子并且理解其行为逻辑，然后在mindspore中查看其相似名称的算子，或者直接搜索算子名，有时候会返回查询算子与pytorch的区别文档。用别人的经验，加速了自己的开发。另外，由于masktextspotter与maskrcnn部分模块多有类似，得益于maskrcnn有mindspore的实现版本，因此在开发过程中也对其多有参考。如果没有在modelzoo里面查询类似的模型，那么也不会有那么多的文档和经验可供借鉴，开发时间将延长。

完成项目大部分模块的开发后，测试的能力被强化。根据要求，开发完成的代码需要完成单元测试，而我采用的是pytest测试各个模块。在与老师的沟通交流中，我明白了构建测试用例不是僵化的，而是使得模块可以根据这个测试用例，得到理想的返回值即可，即使是异常。输出值的验证方法是多样的，无需一定要与pytorch所输出的完全一致，只需实现相同功能的模块在内部逻辑上相同即可。而且由于权重初始化的方法不一样，或者算子缺失而替换成了另一个相似的算子等原因，苛求完全相同的输出意义不大。所以在测试的时候我也关注了这个问题，尽量使得模块可以正常返回理想值。

最后，谈谈需要改进的地方。因为我的主机资源不足，有一些模块尚未被充分测试到，但是大部分模块初始化是没问题的。另外，在数据集的处理上，原来想采用mindrecord对数据做一个转换和存储，但是在读的时候没办法读进来，除了存的数据本身不是二进制以外，还有一个原因就是没办法识别出mindrecord的文件。目前已经用GeneratorDataset代替，但是后续可以继续解决mindrecord问题，因为modelzoo上面很多模型都采用了mindrecord的方法先转换数据集，后续读取的时候可能会有性能上面的提升。至于性能提升，由于本项目代码很多都参考了pytorch的实现逻辑，数据的处理可能会有点混乱，比如有一些模块必须用原生的numpy处理，但是这些数据的处理只是在cpu上面的。后续的开发可以多关注性能调优。

在本项目的开发中，虽有一点不足之处，但是作为前期分析，总体而言完成度较高。除了明白了masktextspotter的模型结构、mindspore对应的开发思路和方法，还增长了测试能力，体会到了开发一个深度学习模型的主要步骤和流程，也运用了不同的文档，有条理地分析和阐述模型的开发工作。在接下来的工作中，将会对模型模块进行调优工作，包括代码的整合和性能的调优。希望接下来的任务会顺利完成！